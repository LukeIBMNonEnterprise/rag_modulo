{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb570d8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### About Retrieval Augmented Generation\n",
    "Retrieval Augmented Generation (RAG) is a versatile pattern that can unlock a number of use cases requiring factual recall of information, such as querying a knowledge base in natural language.\n",
    "\n",
    "In its simplest form, RAG requires 3 steps:\n",
    "\n",
    "- Index knowledge base passages (once)\n",
    "- Retrieve relevant passage(s) from knowledge base (for every user query)\n",
    "- Generate a response by feeding retrieved passage into a large language model (for every user query)\n",
    "\n",
    "### About cookbook 1.2: watsonx.ai tech preview + Milvus vectordb (long-form question answering)\n",
    "This cookbook is a variant of [cookbook 1.1](/rag-1.1-vectordb.ipynb), focusing on long-form extractive question answering). The main change is the use of Milvus as a vector datastore. This cookbook uses an indexing strategy that allows Milvus to perform as well as Chromadb.\n",
    "\n",
    "Users may want to chain the answer generated with this RAG pattern to another LLM prompt that helps paraphrase the answer according to a desired template. \n",
    "\n",
    "### About the example dataset\n",
    "The dataset used in this cookbook is a subset of [nq_open](https://huggingface.co/datasets/nq_open), an open-source question answering dataset based on contents from Wikipedia. The selected subset includes the gold standard passages to answer the queries in the dataset, which enables evaluating the retrieval quality.\n",
    "\n",
    "You can select one of the two dataset available:\n",
    "1. **nq910** - an information retrieval (a.k.a. search) data set extracted from Google's Natural Questions dataset. This dataset is an example of extractive, short-form question answering.\n",
    "2. **LongNQ** - an end-to-end retrieval and answer dataset extracted from the same NQ dataset, but focused more on abstractive, longer-form question answering. The answers were modified for fluency by IBM Research. This is the default dataset for this pattern.\n",
    "\n",
    "These datasets are available in the [data/rag](data/rag/) folder.\n",
    "\n",
    "**Disclaimer: to use this cookbook you need a REST API key compatible with ibm-generative-ai SDK. Note that this API is currently in Beta and will change in the future.**\n",
    "\n",
    "### Limitations\n",
    "Given that we are leveraging a locally-hosted embedding model, data ingestion and querying speeds can be slow.\n",
    "\n",
    "### Cookbook Structure\n",
    "1. Set-up dependencies\n",
    "2. Index knowledge base <br>\n",
    "3. Generate a retrieval-augmented response <br>\n",
    "4. Evaluate RAG performance on your data <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2779f7317a709993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve code auto-completion by disabling\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa972b",
   "metadata": {},
   "source": [
    "# 1. Set-up dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae50a6",
   "metadata": {},
   "source": [
    "### 1.1 Install the required dependencies\n",
    "\n",
    "Note that `ibm-generative-ai` requires `python>=3.9` and `pip>=22.0.1`. A user may need to make sure these pre-requisites are met before using this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f340552451d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: unitxt in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (1.8.1)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from unitxt) (2.19.1)\n",
      "Requirement already satisfied: evaluate in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from unitxt) (0.4.2)\n",
      "Requirement already satisfied: absl-py in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from unitxt) (2.1.0)\n",
      "Requirement already satisfied: ipadic in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from unitxt) (1.0.0)\n",
      "Requirement already satisfied: scipy in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from unitxt) (1.13.0)\n",
      "Requirement already satisfied: filelock in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.16.0->unitxt) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (0.23.0)\n",
      "Requirement already satisfied: packaging in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from datasets>=2.16.0->unitxt) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unitxt) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unitxt) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unitxt) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unitxt) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unitxt) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.2->datasets>=2.16.0->unitxt) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests>=2.19.0->datasets>=2.16.0->unitxt) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests>=2.19.0->datasets>=2.16.0->unitxt) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests>=2.19.0->datasets>=2.16.0->unitxt) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests>=2.19.0->datasets>=2.16.0->unitxt) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unitxt) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unitxt) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unitxt) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unitxt) (1.16.0)\n",
      "Requirement already satisfied: ibm-generative-ai in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: aiolimiter<2.0.0,>=1.1.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from ibm-generative-ai) (1.1.0)\n",
      "Requirement already satisfied: deprecated<2.0.0,>=1.2.14 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from ibm-generative-ai) (1.2.14)\n",
      "Requirement already satisfied: httpx<0.27.0,>=0.26.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from ibm-generative-ai) (0.26.0)\n",
      "Requirement already satisfied: httpx-sse<0.4.0,>=0.3.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from ibm-generative-ai) (0.3.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from ibm-generative-ai) (2.7.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from deprecated<2.0.0,>=1.2.14->ibm-generative-ai) (1.16.0)\n",
      "Requirement already satisfied: anyio in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from httpx<0.27.0,>=0.26.0->ibm-generative-ai) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from httpx<0.27.0,>=0.26.0->ibm-generative-ai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from httpx<0.27.0,>=0.26.0->ibm-generative-ai) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from httpx<0.27.0,>=0.26.0->ibm-generative-ai) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from httpx<0.27.0,>=0.26.0->ibm-generative-ai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.27.0,>=0.26.0->ibm-generative-ai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->ibm-generative-ai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->ibm-generative-ai) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->ibm-generative-ai) (4.11.0)\n",
      "Requirement already satisfied: pymilvus in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: setuptools>=67 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (69.5.1)\n",
      "Requirement already satisfied: grpcio<=1.60.0,>=1.49.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (1.60.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (5.26.1)\n",
      "Requirement already satisfied: environs<=9.5.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (5.9.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (2.2.2)\n",
      "Requirement already satisfied: requests in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (2.31.0)\n",
      "Requirement already satisfied: minio>=7.0.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (7.2.7)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (16.0.0)\n",
      "Requirement already satisfied: azure-storage-blob in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (12.19.1)\n",
      "Requirement already satisfied: scipy in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pymilvus) (1.13.0)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from environs<=9.5.0->pymilvus) (3.21.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from environs<=9.5.0->pymilvus) (1.0.1)\n",
      "Requirement already satisfied: certifi in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from minio>=7.0.0->pymilvus) (2024.2.2)\n",
      "Requirement already satisfied: urllib3 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from minio>=7.0.0->pymilvus) (2.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from minio>=7.0.0->pymilvus) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from minio>=7.0.0->pymilvus) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from minio>=7.0.0->pymilvus) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from azure-storage-blob->pymilvus) (1.30.1)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from azure-storage-blob->pymilvus) (42.0.7)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from azure-storage-blob->pymilvus) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests->pymilvus) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests->pymilvus) (3.7)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->pymilvus) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from cryptography>=2.1.4->azure-storage-blob->pymilvus) (1.16.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus) (24.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from argon2-cffi->minio>=7.0.0->pymilvus) (21.2.0)\n",
      "Requirement already satisfied: pycparser in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->pymilvus) (2.22)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.56-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.56-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.30-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (253 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.8/253.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, SQLAlchemy, packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed SQLAlchemy-2.0.30 dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langsmith-0.1.56 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 tenacity-8.3.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install python-dotenv\n",
    "!pip install pandas\n",
    "!pip install unitxt\n",
    "!pip install --upgrade ibm-generative-ai\n",
    "!pip install pymilvus\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a7e72",
   "metadata": {},
   "source": [
    "### 1.2. Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "975528f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from genai import Client, Credentials\n",
    "from genai.schema import (\n",
    "    TextEmbeddingParameters,\n",
    "    TextGenerationParameters,\n",
    "    DecodingMethod,\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pymilvus import (\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    FieldSchema,\n",
    "    connections,\n",
    "    utility,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "from unitxt import add_to_catalog\n",
    "from unitxt.eval_utils import evaluate\n",
    "from unitxt.metrics import MetricPipeline\n",
    "from unitxt.operators import CopyFields\n",
    "\n",
    "logging.getLogger(\"unitxt\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57832b9",
   "metadata": {},
   "source": [
    "### 1.3. Load credentials for `ibm-generative-ai`\n",
    "\n",
    "Your `.env` file needs to have the following lines without spaces around `=`.\n",
    "\n",
    "```\n",
    "GENAI_KEY=your-genai-key\n",
    "GENAI_API=your-genai-api\n",
    "```\n",
    "\n",
    "By default, `IBM-Generative-AI` will automatically use the following API endpoint: `https://bam-api.res.ibm.com`. However, if you wish to target a different Gen AI API, you can do so by providing a custom API endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a839010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your API endpoint is: https://bam-api.res.ibm.com\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "creds = Credentials.from_env()\n",
    "if creds.api_endpoint:\n",
    "    print(f\"Your API endpoint is: {creds.api_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc3c782ee3d47c",
   "metadata": {},
   "source": [
    "### 1.4. Initialize SDK Client `ibm-generative-ai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1b80e1ebfbd9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(credentials=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a1a9c",
   "metadata": {},
   "source": [
    "# 2. Index knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541d9f0",
   "metadata": {},
   "source": [
    "### 2.1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12816fda",
   "metadata": {},
   "source": [
    "Select one of the two dataset available:\n",
    "1. *nq910* - an Information Retrieval (a.k.a. search) data set extracted from Google's Natural Questions dataset.\n",
    "2. *LongNQ* - an end-to-end retrieval and answer dataset extracted from the same NQ dataset, but focused more on abstractive question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2612737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: ./data/rag/LongNQ_docs\n",
      "Selected dataset: LongNQ_docs\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"LongNQ\", \"nq910\", \"LongNQ_docs\"]\n",
    "dataset = datasets[2]  # The current dataset to use\n",
    "data_root = \"./data/rag\"\n",
    "data_dir = os.path.join(data_root, dataset)\n",
    "\n",
    "print (\"Data directory:\", data_dir)\n",
    "print(\"Selected dataset:\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f14a4cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/rag/LongNQ_docs.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m     qas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestions.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m     13\u001b[0m         columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m psgs, qas\n\u001b[0;32m---> 19\u001b[0m documents, questions \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m, in \u001b[0;36mload_data_v1\u001b[0;34m(data_dir, data_root)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(data_dir):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Try to unzip the directory\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZipFile\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zObject:\n\u001b[1;32m      7\u001b[0m         zObject\u001b[38;5;241m.\u001b[39mextractall(data_root)\n\u001b[1;32m      9\u001b[0m psgs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsgs.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/zipfile/__init__.py:1331\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/rag/LongNQ_docs.zip'"
     ]
    }
   ],
   "source": [
    "def load_data_v1(data_dir, data_root):\n",
    "    if not os.path.exists(data_dir):\n",
    "        # Try to unzip the directory\n",
    "        from zipfile import ZipFile\n",
    "\n",
    "        with ZipFile(data_dir + \".zip\", \"r\") as zObject:\n",
    "            zObject.extractall(data_root)\n",
    "\n",
    "    psgs = pd.read_csv(os.path.join(data_dir, \"psgs.tsv\"), sep=\"\\t\", header=0)\n",
    "    # psgs['indextext'] = psgs['title'].astype(str) + \"\\n\" + psgs['text'] -JS Don't think we need?\n",
    "\n",
    "    qas = pd.read_csv(os.path.join(data_dir, \"questions.tsv\"), sep=\"\\t\", header=0).rename(\n",
    "        columns={\"text\": \"question\", \"id\": \"qid\"}\n",
    "    )\n",
    "\n",
    "    return psgs, qas\n",
    "\n",
    "\n",
    "documents, questions = load_data_v1(data_dir, data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861daa2-d5d1-4817-bef7-43ad473f40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08267b49-ebbc-42a4-9f10-50a295b78e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb6586",
   "metadata": {},
   "source": [
    "\n",
    "The dataset we are using is already chunked into self-contained passages that can be ingested by a vector store.\n",
    "\n",
    "The size of each passage is limited by the embedding model's context window (which is 256 tokens for `all-MiniLM-L6-v2`).\n",
    "\n",
    "In case your dataset requires chunking, it is recommended to chunk according to the document's structure and include contextual metadata such as a title for each passage. You may need to include a stride window for lengthier passages if there is a risk of cutting off important context. There is usually some experimentation required to get chunking right. It's helpful to have a test dataset to evaluate the impact of passage chunking on the retrieval quality (see section 4.1.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d313c0",
   "metadata": {},
   "source": [
    "### 2.2. Create embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function that converts the texts to embeddings\n",
    "\n",
    "\n",
    "def get_embeddings(texts: list[str]):\n",
    "    embeddings: list[list[str]] = []\n",
    "    for response in client.text.embedding.create(\n",
    "        model_id=\"sentence-transformers/all-minilm-l6-v2\",\n",
    "        inputs=texts,\n",
    "        parameters=TextEmbeddingParameters(truncate_input_tokens=True),\n",
    "    ):\n",
    "        embeddings.extend(response.results)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a50b67",
   "metadata": {},
   "source": [
    "### 2.3 Start Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5631d85",
   "metadata": {},
   "source": [
    "Start the Milvus embedded server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if default_server.running is not True:\n",
    "    default_server.start()\n",
    "    print(\"Server should have now started\")\n",
    "else:\n",
    "    default_server.stop()\n",
    "    default_server.cleanup()\n",
    "    default_server.start()\n",
    "    print(\"Server is already running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0fc74",
   "metadata": {},
   "source": [
    "Establish a connection with the embedded server and print its version information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(host=\"localhost\", port=default_server.listen_port)\n",
    "print(utility.get_server_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fbd83",
   "metadata": {},
   "source": [
    "### 2.4 Define a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ac535",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = dataset + \"_collection\"\n",
    "INDEX_NAME = dataset + \"_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210cbeaa-0ea5-472a-b88a-b9140dc77920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you want to drop your old data\n",
    "try:\n",
    "    utility.drop_collection(COLLECTION_NAME)\n",
    "    print(\"Collection has been deleted\")\n",
    "except:  # noqa: E722\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d49b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = FieldSchema(\n",
    "    name=\"id\",\n",
    "    dtype=DataType.INT64,\n",
    "    is_primary=True,\n",
    "    auto_id=True,\n",
    ")\n",
    "\n",
    "text = FieldSchema(\n",
    "    name=\"text\",\n",
    "    dtype=DataType.VARCHAR,\n",
    "    max_length=4096,\n",
    ")\n",
    "\n",
    "text_vector = FieldSchema(name=\"text_vector\", dtype=DataType.FLOAT_VECTOR, dim=384)\n",
    "\n",
    "qid = FieldSchema(name=\"qid\", dtype=DataType.INT64)\n",
    "\n",
    "title = FieldSchema(\n",
    "    name=\"title\",\n",
    "    dtype=DataType.VARCHAR,\n",
    "    max_length=4096,\n",
    ")\n",
    "\n",
    "schema = CollectionSchema(\n",
    "    fields=[id, text, text_vector, qid, title],\n",
    "    description=\"Demo vector store\",\n",
    "    enable_dynamic_field=True,\n",
    ")\n",
    "\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema, using=\"default\", shards_num=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8a329",
   "metadata": {},
   "source": [
    "###  2.5 Prepare collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84b0a4",
   "metadata": {},
   "source": [
    "Prepare the embeddings, texts, titles and question id's for insertion in collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49dc255",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=20, length_function=len, add_start_index=False\n",
    ")\n",
    "\n",
    "\n",
    "def split_and_prepare_document_new(qid: str, title: str, text: str):\n",
    "    split_text = [text.page_content for text in text_splitter.create_documents([text])]\n",
    "    ids = [qid] * len(split_text)\n",
    "    titles = [title] * len(split_text)\n",
    "    embeddings = get_embeddings(split_text)\n",
    "    return split_text, ids, titles, embeddings\n",
    "\n",
    "\n",
    "def process_batch(document_list):\n",
    "    batch_results = []\n",
    "\n",
    "    for id, title, text in zip(\n",
    "        document_list[\"id\"].values.tolist(),\n",
    "        document_list[\"title\"].values.tolist(),\n",
    "        document_list[\"text\"].values.tolist(),\n",
    "    ):\n",
    "        for sub_text, sub_id, sub_title, sub_embedding in zip(*split_and_prepare_document_new(id, title, text)):\n",
    "            batch_results.append(tuple((sub_id, sub_title, sub_text, sub_embedding)))\n",
    "    return batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68440a77a7a7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 10\n",
    "processed_docs = []\n",
    "cache_filename = Path(\"data/.cache/rag-1.2-prepared-docs.pkl\")\n",
    "allow_cache = True\n",
    "\n",
    "if allow_cache and cache_filename.exists():\n",
    "    print(\"Prepared docs cache file exists, loading.\")\n",
    "    with open(cache_filename, \"rb+\") as f:\n",
    "        processed_docs = pickle.load(f)\n",
    "\n",
    "    print(\"Processed docs loaded from pickle checkpoint\")\n",
    "else:\n",
    "    for i in tqdm(range(0, len(documents), batch_size), desc=\"Processing Documents in Batches\"):\n",
    "        # find end of batch\n",
    "        i_end = min(i + batch_size, len(documents))\n",
    "        documents_batch = documents[i:i_end]\n",
    "\n",
    "        # Process the batch\n",
    "        processed = process_batch(documents_batch)\n",
    "        processed_docs.extend(processed)\n",
    "\n",
    "    # Save results for potential reuse\n",
    "    cache_filename.parent.mkdir(exist_ok=True, parents=True)\n",
    "    with open(cache_filename, \"wb+\") as f:\n",
    "        pickle.dump(processed_docs, f)\n",
    "\n",
    "    print(\"Processed docs saved to pickle checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d513d4d",
   "metadata": {},
   "source": [
    "Insert the embeddings, texts, titles and question id's in collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if default_server.running:\n",
    "    collection = Collection(COLLECTION_NAME)\n",
    "\n",
    "    batch_size = 500\n",
    "    for i in tqdm(\n",
    "        range(0, len(processed_docs), batch_size),\n",
    "        desc=\"Inserting documents batches to Milvus VectorDB\",\n",
    "    ):\n",
    "        # find end of batch\n",
    "        i_end = min(i + batch_size, len(processed_docs))\n",
    "        id_l, title_l, text_l, embed_l = list(zip(*processed_docs[i:i_end]))\n",
    "\n",
    "        data_to_insert = [text_l, embed_l, id_l, title_l]\n",
    "        try:\n",
    "            collection.insert(data_to_insert)\n",
    "        except Exception as ex:\n",
    "            print(f\"Failed to insert: {ex}\")\n",
    "            print(title_l)\n",
    "else:\n",
    "    print(\"Milvus server is not running! Rerun related notebook cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d7c2b",
   "metadata": {},
   "source": [
    "Create an index on vector field (the one containing the embeddings)\n",
    "\n",
    "**NOTE: use HNSW as the index type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLIST_SIZE = 1024\n",
    "\n",
    "index_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"index_type\": \"HNSW\",\n",
    "    \"params\": {\"nlist\": NLIST_SIZE},\n",
    "    \"M\": 16,\n",
    "    \"efConstruction\": 200,\n",
    "}\n",
    "\n",
    "collection.create_index(field_name=\"text_vector\", index_params=index_params)\n",
    "\n",
    "print(\"Collection index has been successfully created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad9d3e",
   "metadata": {},
   "source": [
    "# 3. Generate a retrieval-augmented response to a question "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd72043",
   "metadata": {},
   "source": [
    "### 3.1. Setup Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bbdb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of supported models from the API\n",
    "models = pd.DataFrame(data=(model.model_dump() for model in client.model.list().results))\n",
    "models = models.set_index(\"id\")\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select generative model to use\n",
    "model_id = \"google/flan-ul2\"\n",
    "parameters = TextGenerationParameters(decoding_method=DecodingMethod.GREEDY, max_new_tokens=100, min_new_tokens=1)\n",
    "\n",
    "# Find model token limit\n",
    "model_token_limit = models.loc[model_id].token_limits[0][\"token_limit\"]\n",
    "print(f\"Model token limit:  {model_token_limit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b2121-280d-4cb4-ae12-8f34a826bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up inference parameters\n",
    "parameters = TextGenerationParameters(decoding_method=DecodingMethod.GREEDY, max_new_tokens=100, min_new_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c448f",
   "metadata": {},
   "source": [
    "The input token limit depends on the selected generative model's max sequence length. The total input tokens in the RAG prompt should not exceed the model's max sequence length minus the number of desired output tokens. The choice of the number of paragraphs to retrieve as context impacts the number tokens in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c755946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For setting the input token limit we subtract the max_new_tokens (to be generated) and -1 from the model_token_limit\n",
    "input_token_limit = model_token_limit - parameters.max_new_tokens - 1\n",
    "print(f\"Input token limit: {input_token_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056acd65",
   "metadata": {},
   "source": [
    "### 3.2. Select a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "qidx = 2\n",
    "question_text = questions.question[qidx].strip(\"?\") + \"?\"\n",
    "question_embeddings = get_embeddings([question_text])[0]\n",
    "print(question_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9fdb71",
   "metadata": {},
   "source": [
    "### 3.3. Retrieve relevant context\n",
    "\n",
    "i.e. Fetch paragraphs similar to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6713ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.load()\n",
    "search_params = {\"metric_type\": \"L2\", \"params\": {\"ef\": 10}}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RetrievedContext:\n",
    "    id: int\n",
    "    text: str\n",
    "    title: str\n",
    "    distance: Optional[float] = None\n",
    "\n",
    "\n",
    "def query_documents(question_text: str, n_results=5) -> list[RetrievedContext]:\n",
    "    question_embedding = get_embeddings([question_text])[0]\n",
    "    response = collection.search(\n",
    "        data=[question_embedding],\n",
    "        anns_field=\"text_vector\",\n",
    "        param=search_params,\n",
    "        limit=4,\n",
    "        expr=None,\n",
    "        output_fields=[\n",
    "            \"qid\",\n",
    "            \"text\",\n",
    "            \"title\",\n",
    "        ],  # name of the field to retrieve from the search result\n",
    "        consistency_level=\"Strong\",\n",
    "    )\n",
    "    results = []\n",
    "    for raw_results in response:\n",
    "        for document in raw_results:\n",
    "            results.append(\n",
    "                RetrievedContext(\n",
    "                    id=document.entity.get(\"qid\"),\n",
    "                    text=document.entity.get(\"text\"),\n",
    "                    title=document.entity.get(\"title\"),\n",
    "                    distance=document.distance,\n",
    "                )\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cf551",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_documents = query_documents(question_text)\n",
    "pd.DataFrame(relevant_documents).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02484a",
   "metadata": {},
   "source": [
    "### 3.4. Feed the context and the question to `genai` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d959268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token counting function\n",
    "def token_count(doc: str):\n",
    "    response = list(client.text.tokenization.create(input=[doc], model_id=model_id))\n",
    "    return response[0].results[0].token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874536df",
   "metadata": {},
   "source": [
    "`prompt_template` is a function to create a prompt from the given context and question. Changing the prompt will sometimes result in much more appropriate answers (or it may degrade the quality significantly). The prompt template below is most appropriate for short-form extractive use cases.\n",
    "\n",
    "`make_prompt` includes a script to truncate the context length provided as an input in case the total token inputs exceed the model's limit. The paragraphs with the largest distance are truncated first. This functionality is helpful in case the embedded passages are not of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template(context, question_text):\n",
    "    return (\n",
    "        f'Please answer the question using the context provided. If the question is unanswerable, say \"unanswerable\". Question: {question_text}.\\n\\n'\n",
    "        + \"Context:\\n\\n\"\n",
    "        + f\"{context}:\\n\\n\"\n",
    "        + f'Question: {question_text}. If the question is unanswerable, say \"unanswerable\".'\n",
    "    )\n",
    "\n",
    "\n",
    "def make_prompt(\n",
    "    relevant_documents: list[RetrievedContext],\n",
    "    question_text: str,\n",
    "    max_input_tokens: int,\n",
    "):\n",
    "    context = \"\\n\\n\\n\".join(doc.text for doc in relevant_documents)\n",
    "    prompt = prompt_template(context, question_text)\n",
    "\n",
    "    prompt_token_count = token_count(prompt)\n",
    "\n",
    "    if prompt_token_count <= max_input_tokens:\n",
    "        return prompt\n",
    "\n",
    "    print(\"exceeded input token limit, truncating context\", prompt_token_count)\n",
    "    distances = [doc.distance for doc in relevant_documents]\n",
    "    documents = [doc.text for doc in relevant_documents]\n",
    "\n",
    "    # documents with the lower distance scores are included in the truncated context first\n",
    "    sorted_indices = sorted(range(len(distances)), key=lambda k: distances[k])\n",
    "\n",
    "    truncated_context = \"\"\n",
    "    token_count_so_far = 0\n",
    "    i = 0\n",
    "\n",
    "    while token_count_so_far <= max_input_tokens and i < len(sorted_indices):\n",
    "        doc_index = sorted_indices[i]\n",
    "        document = documents[doc_index]\n",
    "        doc_token_count = token_count(document)\n",
    "\n",
    "        if token_count_so_far + doc_token_count <= max_input_tokens:\n",
    "            truncated_context += document + \"\\n\\n\\n\"\n",
    "            token_count_so_far += doc_token_count\n",
    "        else:\n",
    "            remaining_tokens = max_input_tokens - token_count_so_far\n",
    "            truncated_context += document[:remaining_tokens]\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return prompt_template(truncated_context, question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = make_prompt(relevant_documents, question_text, input_token_limit)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754300cc",
   "metadata": {},
   "source": [
    "**Generate response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = list(client.text.generation.create(model_id=model_id, inputs=prompt, parameters=parameters))\n",
    "response = responses[0].results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question = \", question_text)\n",
    "print(\"Answer = \", response.generated_text)\n",
    "print(\n",
    "    \"Expected Answer(s) (may not appear with exact wording in the dataset) = \",\n",
    "    questions.answers[qidx],\n",
    ")\n",
    "print(f\"QUID: {qidx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5781d5d34db4c8f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Evaluate RAG performance on your data\n",
    "\n",
    "This step requires having a test dataset that includes for each question:\n",
    "- The indexes of the passage(s) that contain the answer - i.e. the goldstandard passages (if the question is answerable by the knowledge base)\n",
    "- The question's goldstandard answer (this can be short or long-form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570fbcbf69737185",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4.1 Retrieve context documents and generate answers for all questions\n",
    "We will now run the RAG pipeline on the given questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edaca301c78e2c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare all data for evaluation\n",
    "@dataclass\n",
    "class QuestionData:\n",
    "    qid: int  # Question ID\n",
    "    prompt: str  # Generated prompt\n",
    "    question: str  # Original question\n",
    "    ground_truth_contexts: list[str]  # Text content of ground truth contexts\n",
    "    ground_truths_context_ids: list[str]  # IDs of ground truth contexts\n",
    "    contexts: list[str]  # Retrieved contexts from vector database\n",
    "    context_ids: list[int]  # IDs of retrieved contexts\n",
    "    ground_truths: list[str]  # Possible ground truth formulations of answer\n",
    "    answer: Optional[str] = None  # Answer from LLM (will be filled later)\n",
    "\n",
    "\n",
    "# NOTE: Sampling less questions for example purposes.\n",
    "# Change this to len(questions) for full evaluation\n",
    "num_eval_questions = 250\n",
    "eval_questions = questions.sample(num_eval_questions)\n",
    "num_retrieve_relevant = 5\n",
    "\n",
    "prompts = []\n",
    "\n",
    "\n",
    "def to_int(data: list[str]) -> list[int]:\n",
    "    return list(map(int, data))\n",
    "\n",
    "\n",
    "data_for_evaluation: list[QuestionData] = []\n",
    "\n",
    "for _, question in tqdm(eval_questions.iterrows(), total=num_eval_questions):\n",
    "    retrieved_documents = query_documents(question.question, n_results=num_retrieve_relevant)\n",
    "    prompt = make_prompt(retrieved_documents, question.question, input_token_limit)\n",
    "    contexts = [doc.text for doc in retrieved_documents]\n",
    "    context_ids = [doc.id for doc in retrieved_documents]\n",
    "\n",
    "    relevant_documents = to_int(str(question.relevant).split(\",\"))\n",
    "    # Filter out unanswerable questions (-1 means that no relevant context exists)\n",
    "    relevant_documents = [document_id for document_id in relevant_documents if document_id >= 0]\n",
    "    ground_truth_contexts = [documents.set_index(\"id\").loc[document_id].text for document_id in relevant_documents]\n",
    "    ground_truths_context_ids = relevant_documents\n",
    "    ground_truths = str(question.answers).split(\"::\")\n",
    "    # Filter out unanswerable questions ('-' means that no relevant answer exists)\n",
    "    if ground_truths == [\"-\"]:\n",
    "        ground_truths = [\"unanswerable\"]\n",
    "\n",
    "    data_for_evaluation.append(\n",
    "        QuestionData(\n",
    "            qid=question.qid,\n",
    "            prompt=prompt,\n",
    "            question=question.question,\n",
    "            ground_truth_contexts=ground_truth_contexts,\n",
    "            ground_truths_context_ids=ground_truths_context_ids,\n",
    "            contexts=contexts,\n",
    "            context_ids=context_ids,\n",
    "            ground_truths=ground_truths,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8191e0f1f4a1a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate answers by LLM\n",
    "new_data_for_evaluation = []\n",
    "inputs = [datapoint.prompt for datapoint in data_for_evaluation]\n",
    "for idx, response in tqdm(\n",
    "    enumerate(client.text.generation.create(model_id=model_id, inputs=inputs, parameters=parameters)),\n",
    "    total=len(eval_questions),\n",
    "):\n",
    "    data_for_evaluation[idx].answer = response.results[0].generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e866685c9adb7c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create final Data frame for evaluation\n",
    "data_frame_for_evaluation = pd.DataFrame(data_for_evaluation).set_index(\"qid\")\n",
    "data_frame_for_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a427e1c0496af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4.2 Evaluate Retrieval quality\n",
    "\n",
    "There are many ways to compute retrieval quality, namely how the information contained in the documents that are relevant to the question being asked. We're focusing here on success at given number of returns  (aka recall at given levels), which is to say, given a fixed number of documents returned (e.g., 1, 3, 5), is the question's answer contained in them. The scores increase with the recall level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c77a031fed5d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare custom unitxt metrics\n",
    "recall_levels = [1, 3, 5]\n",
    "for recall_level in recall_levels:\n",
    "    metric = MetricPipeline(\n",
    "        main_score=f\"recall_at_{recall_level}\",\n",
    "        preprocess_steps=[\n",
    "            CopyFields(field_to_field=[(\"context_ids\", \"prediction\")], use_query=True),\n",
    "            CopyFields(\n",
    "                field_to_field=[(\"ground_truths_context_ids\", \"references\")],\n",
    "                use_query=True,\n",
    "            ),\n",
    "        ],\n",
    "        metric=\"metrics.retrieval_at_k\",\n",
    "    )\n",
    "    add_to_catalog(metric, f\"metrics.rag.recall_at_{recall_level}\", overwrite=True)\n",
    "\n",
    "\n",
    "def evaluate_metrics(data: pd.DataFrame, metric_names: list[str]):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        result_df = evaluate(data, metric_names=metric_names)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a76662cd07a09",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recall_metric_names = [f\"metrics.rag.recall_at_{level}\" for level in recall_levels]\n",
    "# Filter out questions with no relevant context\n",
    "non_empty_context_mask = data_frame_for_evaluation.ground_truth_contexts.apply(lambda x: len(x) > 0)\n",
    "result_df = evaluate_metrics(data_frame_for_evaluation[non_empty_context_mask], recall_metric_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734d7387f22ea34",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Note**: \n",
    "We do not take into account chunking in the evaluation.\n",
    "Because the model can retrieve multiple paragraphs from a single document, and we do not have the ground truth passages per document, the recall metric can grow above 1.\n",
    "Therefore, the numbers are more heuristic and not directly compareable to other notebooks.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2ce14c70b28f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = result_df[recall_metric_names].mean().plot(kind=\"bar\")\n",
    "ax.set_xticklabels(f\"Recall at {k}\" for k in recall_levels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c56582bd17525",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4.2 Evaluate answered and unanswered questions\n",
    "The following table breaks the count of question/answer pairs by whether the test dataset has an answer (rows) and the RAG model returned an answer (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90526d2cef24992",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer_matrix = pd.crosstab(\n",
    "    data_frame_for_evaluation.answer != \"unanswerable\",  # Question was answered\n",
    "    data_frame_for_evaluation.ground_truths.apply(lambda x: x != [\"unanswerable\"]),\n",
    "    rownames=[\"System\"],\n",
    "    colnames=[\"Ground Truth\"],\n",
    ")\n",
    "answer_matrix = answer_matrix.rename({True: \"Answered\", False: \"Not answered\"})\n",
    "answer_matrix = answer_matrix.rename(columns={True: \"Has answer\", False: \"No answer\"})\n",
    "answer_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc5a272446517c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.3 Complex evaluation of retrieval quality and generated answers\n",
    "We will leverage [unitxt](https://github.com/IBM/unitxt) metrics to evaluate the system in a more robust, complex way.\n",
    "Please refer to [this document](https://github.ibm.com/conversational-ai/rag-metrics/blob/d771becd557d01d9c20a7479b3883b9c40d9fde6/README.md) to see the full explanation of the metrics.\n",
    "\n",
    "(Can take several minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3030650b6e0e3c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric_names = [\n",
    "    \"metrics.rag.mrr\",\n",
    "    \"metrics.rag.map\",\n",
    "    \"metrics.rag.context_correctness\",\n",
    "    \"metrics.rag.context_perplexity\",\n",
    "    \"metrics.rag.context_relevance\",\n",
    "    \"metrics.rag.faithfulness\",  # Requires both context and answer, but it makes sense only for answerable questions\n",
    "]\n",
    "# Evaluate metrics that take into account only context on answerable questions,\n",
    "# because their score for an unanswerable question is always 0\n",
    "result_df = evaluate_metrics(data_frame_for_evaluation[non_empty_context_mask], metric_names)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21b3c3c541eea1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df[\"metrics.rag.context_perplexity\"] = result_df[\"metrics.rag.context_perplexity\"].apply(\n",
    "    lambda perplexities: np.mean(perplexities)\n",
    ")\n",
    "result_df[metric_names].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671a5cddc6bf51b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric_names = [\n",
    "    \"metrics.rag.answer_reward\",\n",
    "    \"metrics.rag.answer_correctness\",\n",
    "]\n",
    "# Evaluate metrics that take into account answers on all questions\n",
    "result_df = evaluate_metrics(data_frame_for_evaluation, metric_names)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cafce9f4d1f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df[metric_names].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
